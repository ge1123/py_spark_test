# version: '3.8'

services:
  spark:
    build:
      context: .
      dockerfile: spark.dockerfile
    container_name: spark
    environment:
      SPARK_MODE: master
      HOME: "/tmp"
      SPARK_SUBMIT_OPTIONS: >
          --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
          --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
          --conf spark.sql.catalogImplementation=hive
          --conf spark.sql.warehouse.dir=/opt/spark-warehouse
    ports:
    - "4040:4040"
    - "8080:8080"
    volumes:
      - .:/opt/project
      - ~/spark_data:/data
      - ~/spark_warehouse:/opt/spark-warehouse  # ✅ Hive metadata 永久儲存

